{"cells":[{"cell_type":"markdown","id":"ae5c3947-426a-4738-9bc7-0220929193fc","metadata":{"language":"python"},"source":"# RAG with LangChain"},{"cell_type":"markdown","id":"7a6ae9ee-8ad4-40dd-90d6-e11f9d668a7f","metadata":{"language":"python"},"source":"![RAG with LangChain](https://showme.redstarplugin.com/d/d:veju38cL)"},{"cell_type":"markdown","id":"3c6b435e-d330-4211-a006-eb8a5ef53291","metadata":{"language":"python"},"source":"The \"LangChain with RAG\" tutorial likely explains how to integrate LangChain, a framework for building language models, with Retrieval-Augmented Generation (RAG), a method that enhances language models by retrieving and incorporating contextually relevant responses."},{"cell_type":"markdown","id":"0817a010-b17f-41cb-a0bd-2697136654e6","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:59:28.982962Z","iopub.status.busy":"2023-12-20T06:59:28.982682Z","iopub.status.idle":"2023-12-20T06:59:28.985757Z","shell.execute_reply":"2023-12-20T06:59:28.985133Z","shell.execute_reply.started":"2023-12-20T06:59:28.982940Z"},"language":"python"},"source":"### Install necessary packages and libraries "},{"cell_type":"code","execution_count":7,"id":"060248da-12c9-4466-8eb7-a631607079d7","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:39:44.532563Z","iopub.status.busy":"2023-12-20T06:39:44.532296Z","iopub.status.idle":"2023-12-20T06:39:46.622466Z","shell.execute_reply":"2023-12-20T06:39:46.621861Z","shell.execute_reply.started":"2023-12-20T06:39:44.532544Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: langchain in /opt/conda/lib/python3.11/site-packages (0.0.351)\nRequirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (1.6.0)\nRequirement already satisfied: faiss-cpu in /opt/conda/lib/python3.11/site-packages (1.7.4)\nRequirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (0.5.2)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.21)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.6.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.33)\nRequirement already satisfied: langchain-community<0.1,>=0.0.2 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.0.4)\nRequirement already satisfied: langchain-core<0.2,>=0.1 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.1.1)\nRequirement already satisfied: langsmith<0.1.0,>=0.0.70 in /opt/conda/lib/python3.11/site-packages (from langchain) (0.0.72)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (1.26.0)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.5.2)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.8.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.25.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.66.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.9.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken) (2023.10.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\nRequirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.5 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.14.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.2.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.1.0)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"}],"source":"!pip install langchain openai faiss-cpu tiktoken"},{"cell_type":"code","execution_count":12,"id":"d91cf497-2513-43f7-9d91-cc92809aa514","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:40:59.863949Z","iopub.status.busy":"2023-12-20T06:40:59.863694Z","iopub.status.idle":"2023-12-20T06:41:00.320179Z","shell.execute_reply":"2023-12-20T06:41:00.319711Z","shell.execute_reply.started":"2023-12-20T06:40:59.863931Z"},"language":"python","trusted":true},"outputs":[],"source":"from operator import itemgetter\n\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.vectorstores import FAISS\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough"},{"cell_type":"code","execution_count":49,"id":"d888c9ce-d6b8-43b1-8bcf-3af2c7db0004","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:44:48.198640Z","iopub.status.busy":"2023-12-20T06:44:48.198358Z","iopub.status.idle":"2023-12-20T06:44:48.201413Z","shell.execute_reply":"2023-12-20T06:44:48.200775Z","shell.execute_reply.started":"2023-12-20T06:44:48.198615Z"},"language":"python","trusted":true},"outputs":[],"source":"import os\nos.environ[\"OPENAI_API_KEY\"] = \"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\""},{"cell_type":"code","execution_count":50,"id":"f9f1290e-09a0-4ac2-b95c-fe0049454a29","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:44:51.975659Z","iopub.status.busy":"2023-12-20T06:44:51.975339Z","iopub.status.idle":"2023-12-20T06:44:52.008851Z","shell.execute_reply":"2023-12-20T06:44:52.008417Z","shell.execute_reply.started":"2023-12-20T06:44:51.975633Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.chat_models import ChatOpenAI\n\nllm = ChatOpenAI(openai_api_key=\"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\")"},{"cell_type":"code","execution_count":51,"id":"9f130007-7291-4770-946c-e59bf5811d0e","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:44:56.626913Z","iopub.status.busy":"2023-12-20T06:44:56.626551Z","iopub.status.idle":"2023-12-20T06:44:57.355682Z","shell.execute_reply":"2023-12-20T06:44:57.355193Z","shell.execute_reply.started":"2023-12-20T06:44:56.626894Z"},"language":"python","trusted":true},"outputs":[],"source":"vectorstore = FAISS.from_texts(\n    [\"Pavan works at SingleStore as a Technology Evangelist\"], embedding=OpenAIEmbeddings()\n)\nretriever = vectorstore.as_retriever()\n\ntemplate = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nmodel = ChatOpenAI()"},{"cell_type":"code","execution_count":61,"id":"2eac171b-cfbd-4a0f-a83f-f3a66a24957c","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:45:38.770792Z","iopub.status.busy":"2023-12-20T06:45:38.770496Z","iopub.status.idle":"2023-12-20T06:45:38.774402Z","shell.execute_reply":"2023-12-20T06:45:38.773814Z","shell.execute_reply.started":"2023-12-20T06:45:38.770770Z"},"language":"python","trusted":true},"outputs":[],"source":"chain = (\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n    | prompt\n    | model\n    | StrOutputParser()\n)"},{"cell_type":"code","execution_count":64,"id":"fb21e04d-08e8-4279-8bd6-c701f66232e9","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:46:14.409631Z","iopub.status.busy":"2023-12-20T06:46:14.409380Z","iopub.status.idle":"2023-12-20T06:46:15.313771Z","shell.execute_reply":"2023-12-20T06:46:15.313331Z","shell.execute_reply.started":"2023-12-20T06:46:14.409612Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'Pavan works at SingleStore.'"},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":"chain.invoke(\"where Pavan works?\")"},{"cell_type":"code","execution_count":77,"id":"5a00c1da-4775-426f-b41e-4eeb288ef8be","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:46:58.589601Z","iopub.status.busy":"2023-12-20T06:46:58.589128Z","iopub.status.idle":"2023-12-20T06:46:58.594706Z","shell.execute_reply":"2023-12-20T06:46:58.594263Z","shell.execute_reply.started":"2023-12-20T06:46:58.589577Z"},"language":"python","trusted":true},"outputs":[],"source":"template = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\nAnswer in the following language: {language}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\n        \"context\": itemgetter(\"question\") | retriever,\n        \"question\": itemgetter(\"question\"),\n        \"language\": itemgetter(\"language\"),\n    }\n    | prompt\n    | model\n    | StrOutputParser()\n)"},{"cell_type":"code","execution_count":88,"id":"1c1e1659-65c5-48ce-8a2a-4f3e9f3987ac","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:47:48.488411Z","iopub.status.busy":"2023-12-20T06:47:48.488164Z","iopub.status.idle":"2023-12-20T06:47:51.414527Z","shell.execute_reply":"2023-12-20T06:47:51.413925Z","shell.execute_reply.started":"2023-12-20T06:47:48.488393Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"'ಪವನ್ ಸಿಂಗಲ್\\u200cಮೇಲ್ ತಾಂತ್ರಿಕ ಪ್ರಚಾರಕನಾಗಿ ಕೆಲಸ ಮಾಡುತ್ತಾರೆ.'"},"execution_count":88,"metadata":{},"output_type":"execute_result"}],"source":"chain.invoke({\"question\": \"where Pavan works\", \"language\": \"Kannada\"})"},{"cell_type":"code","execution_count":98,"id":"a711a9f3-75c2-4f9c-bc0e-d978a2725211","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:48:39.526728Z","iopub.status.busy":"2023-12-20T06:48:39.526480Z","iopub.status.idle":"2023-12-20T06:48:40.478984Z","shell.execute_reply":"2023-12-20T06:48:40.478383Z","shell.execute_reply.started":"2023-12-20T06:48:39.526709Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"\"Pavan travaille chez SingleStore en tant qu'évangéliste technologique.\""},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":"chain.invoke({\"question\": \"where Pavan works\", \"language\": \"French\"})"},{"cell_type":"markdown","id":"efadd9f7-ce18-4759-b451-42b2a3ea91eb","metadata":{"language":"python"},"source":"## Conversational Retrieval Chain"},{"cell_type":"markdown","id":"0b887917-89bf-4081-9448-0a348546d75a","metadata":{"language":"python"},"source":"### We can easily add in conversation history. This primarily means adding in chat_message_history"},{"cell_type":"markdown","id":"54f7f032-bea5-49af-935e-d79abf37a158","metadata":{"language":"python"},"source":"The term \"Conversational Retrieval Chain,\" refers to a methodology or process in AI-driven conversational systems where information retrieval is integrated into the generation of conversational responses. This integration enhances the AI's ability to provide more relevant, accurate, and context-aware responses in a conversation. "},{"cell_type":"code","execution_count":120,"id":"ea2b09f4-b126-41f8-9c8e-2cad58877469","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:50:37.265429Z","iopub.status.busy":"2023-12-20T06:50:37.265170Z","iopub.status.idle":"2023-12-20T06:50:37.273062Z","shell.execute_reply":"2023-12-20T06:50:37.272556Z","shell.execute_reply.started":"2023-12-20T06:50:37.265406Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.schema import format_document\nfrom langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\nfrom langchain_core.runnables import RunnableParallel"},{"cell_type":"code","execution_count":122,"id":"56b09517-c1e9-4e93-ae93-ea37e6094e5f","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:51:08.712373Z","iopub.status.busy":"2023-12-20T06:51:08.712112Z","iopub.status.idle":"2023-12-20T06:51:08.715494Z","shell.execute_reply":"2023-12-20T06:51:08.714900Z","shell.execute_reply.started":"2023-12-20T06:51:08.712356Z"},"language":"python","trusted":true},"outputs":[],"source":"from langchain.prompts.prompt import PromptTemplate\n\n_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone question:\"\"\"\nCONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"},{"cell_type":"code","execution_count":123,"id":"a919df25-2b43-46c4-a6fd-ca5ff08237d4","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:51:18.335689Z","iopub.status.busy":"2023-12-20T06:51:18.335460Z","iopub.status.idle":"2023-12-20T06:51:18.339011Z","shell.execute_reply":"2023-12-20T06:51:18.338385Z","shell.execute_reply.started":"2023-12-20T06:51:18.335670Z"},"language":"python","trusted":true},"outputs":[],"source":"template = \"\"\"Answer the question based only on the following context:\n{context}\n\nQuestion: {question}\n\"\"\"\nANSWER_PROMPT = ChatPromptTemplate.from_template(template)"},{"cell_type":"code","execution_count":133,"id":"f3ec3f68-8cfc-4295-8bc0-bacb4dfb7b2b","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:51:30.680818Z","iopub.status.busy":"2023-12-20T06:51:30.680568Z","iopub.status.idle":"2023-12-20T06:51:30.685219Z","shell.execute_reply":"2023-12-20T06:51:30.684617Z","shell.execute_reply.started":"2023-12-20T06:51:30.680803Z"},"language":"python","trusted":true},"outputs":[],"source":"DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n\n\ndef _combine_documents(\n    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n):\n    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n    return document_separator.join(doc_strings)"},{"cell_type":"code","execution_count":134,"id":"fac34fea-9971-4786-8fde-926d489cc6c5","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:51:50.243151Z","iopub.status.busy":"2023-12-20T06:51:50.242897Z","iopub.status.idle":"2023-12-20T06:51:50.293853Z","shell.execute_reply":"2023-12-20T06:51:50.293339Z","shell.execute_reply.started":"2023-12-20T06:51:50.243132Z"},"language":"python","trusted":true},"outputs":[],"source":"_inputs = RunnableParallel(\n    standalone_question=RunnablePassthrough.assign(\n        chat_history=lambda x: get_buffer_string(x[\"chat_history\"])\n    )\n    | CONDENSE_QUESTION_PROMPT\n    | ChatOpenAI(temperature=0)\n    | StrOutputParser(),\n)\n_context = {\n    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n    \"question\": lambda x: x[\"standalone_question\"],\n}\nconversational_qa_chain = _inputs | _context | ANSWER_PROMPT | ChatOpenAI()"},{"cell_type":"code","execution_count":144,"id":"6446b51a-0a9a-45c0-97f9-c1e2d7b59a12","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:52:33.884733Z","iopub.status.busy":"2023-12-20T06:52:33.884297Z","iopub.status.idle":"2023-12-20T06:52:35.171900Z","shell.execute_reply":"2023-12-20T06:52:35.171264Z","shell.execute_reply.started":"2023-12-20T06:52:33.884710Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"AIMessage(content='Pavan works at SingleStore.')"},"execution_count":144,"metadata":{},"output_type":"execute_result"}],"source":"conversational_qa_chain.invoke(\n    {\n        \"question\": \"where Pavan works?\",\n        \"chat_history\": [],\n    }\n)"},{"cell_type":"code","execution_count":156,"id":"fbe28725-658e-4b5d-b2e6-2a26eb745ea5","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:53:46.551672Z","iopub.status.busy":"2023-12-20T06:53:46.551413Z","iopub.status.idle":"2023-12-20T06:53:47.770209Z","shell.execute_reply":"2023-12-20T06:53:47.769739Z","shell.execute_reply.started":"2023-12-20T06:53:46.551648Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"AIMessage(content='Pavan works at SingleStore as a Technology Evangelist.')"},"execution_count":156,"metadata":{},"output_type":"execute_result"}],"source":"conversational_qa_chain.invoke(\n    {\n        \"question\": \"where does he work?\",\n        \"chat_history\": [\n            HumanMessage(content=\"Who wrote this notebook?\"),\n            AIMessage(content=\"Pavan\"),\n        ],\n    }\n)"},{"cell_type":"markdown","id":"a8cc242f-f5ce-45cd-8f27-a6a3e884ca00","metadata":{"language":"python"},"source":"## With Memory and returning source documents"},{"cell_type":"markdown","id":"85249fc0-a5da-407c-b25e-3f156fa1d9cf","metadata":{"language":"python"},"source":"This shows how to use memory with the above. For memory, we need to manage that outside at the memory. For returning the retrieved documents, we just need to pass them through all the way."},{"cell_type":"markdown","id":"19cdb7ef-77a3-4cb9-ae55-52955c52dd3e","metadata":{"language":"python"},"source":"\"With Memory and returning source documents\" in the context of RAG with LangChain refers to the capability of an AI system to recall past interactions for context-aware conversations (Memory) and to provide the source documents it retrieved for information augmentation (returning source documents) during the conversation generation process."},{"cell_type":"code","execution_count":157,"id":"672cbaaf-ed73-44ec-9a1f-c14928d5f4ca","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:54:19.618549Z","iopub.status.busy":"2023-12-20T06:54:19.618306Z","iopub.status.idle":"2023-12-20T06:54:19.850167Z","shell.execute_reply":"2023-12-20T06:54:19.849709Z","shell.execute_reply.started":"2023-12-20T06:54:19.618532Z"},"language":"python","trusted":true},"outputs":[],"source":"from operator import itemgetter\n\nfrom langchain.memory import ConversationBufferMemory"},{"cell_type":"code","execution_count":167,"id":"3c7ddcfa-b59f-4a88-aa69-35bd8c0d603d","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:54:34.018672Z","iopub.status.busy":"2023-12-20T06:54:34.018429Z","iopub.status.idle":"2023-12-20T06:54:34.021432Z","shell.execute_reply":"2023-12-20T06:54:34.020871Z","shell.execute_reply.started":"2023-12-20T06:54:34.018655Z"},"language":"python","trusted":true},"outputs":[],"source":"memory = ConversationBufferMemory(\n    return_messages=True, output_key=\"answer\", input_key=\"question\"\n)"},{"cell_type":"code","execution_count":171,"id":"f8502980-15a6-4805-844e-c6083e6a3a42","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:54:59.841912Z","iopub.status.busy":"2023-12-20T06:54:59.841614Z","iopub.status.idle":"2023-12-20T06:55:00.013656Z","shell.execute_reply":"2023-12-20T06:55:00.013178Z","shell.execute_reply.started":"2023-12-20T06:54:59.841891Z"},"language":"python","trusted":true},"outputs":[],"source":"# First we add a step to load memory\n# This adds a \"memory\" key to the input object\nloaded_memory = RunnablePassthrough.assign(\n    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n)\n# Now we calculate the standalone question\nstandalone_question = {\n    \"standalone_question\": {\n        \"question\": lambda x: x[\"question\"],\n        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n    }\n    | CONDENSE_QUESTION_PROMPT\n    | ChatOpenAI(temperature=0)\n    | StrOutputParser(),\n}\n# Now we retrieve the documents\nretrieved_documents = {\n    \"docs\": itemgetter(\"standalone_question\") | retriever,\n    \"question\": lambda x: x[\"standalone_question\"],\n}\n# Now we construct the inputs for the final prompt\nfinal_inputs = {\n    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n    \"question\": itemgetter(\"question\"),\n}\n# And finally, we do the part that returns the answers\nanswer = {\n    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(),\n    \"docs\": itemgetter(\"docs\"),\n}\n# And now we put it all together!\nfinal_chain = loaded_memory | standalone_question | retrieved_documents | answer"},{"cell_type":"code","execution_count":172,"id":"b4d3ab00-1047-47ee-a42e-5093423c4627","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:55:22.215503Z","iopub.status.busy":"2023-12-20T06:55:22.215220Z","iopub.status.idle":"2023-12-20T06:55:23.513288Z","shell.execute_reply":"2023-12-20T06:55:23.512724Z","shell.execute_reply.started":"2023-12-20T06:55:22.215486Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"{'answer': AIMessage(content='Pavan works at SingleStore.'),\n 'docs': [Document(page_content='Pavan works at SingleStore as a Technology Evangelist')]}"},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":"inputs = {\"question\": \"where Pavan works?\"}\nresult = final_chain.invoke(inputs)\nresult"},{"cell_type":"code","execution_count":182,"id":"04e3336d-1b48-4eaf-bfea-f91d47182458","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:55:48.300521Z","iopub.status.busy":"2023-12-20T06:55:48.300243Z","iopub.status.idle":"2023-12-20T06:55:48.303418Z","shell.execute_reply":"2023-12-20T06:55:48.302871Z","shell.execute_reply.started":"2023-12-20T06:55:48.300502Z"},"language":"python","trusted":true},"outputs":[],"source":"# Note that the memory does not save automatically\n# This will be improved in the future\n# For now you need to save it yourself\nmemory.save_context(inputs, {\"answer\": result[\"answer\"].content})"},{"cell_type":"code","execution_count":183,"id":"73e37543-6e95-4a04-a1ea-e703cb044f93","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:56:00.610908Z","iopub.status.busy":"2023-12-20T06:56:00.610402Z","iopub.status.idle":"2023-12-20T06:56:00.614703Z","shell.execute_reply":"2023-12-20T06:56:00.614123Z","shell.execute_reply.started":"2023-12-20T06:56:00.610883Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"{'history': [HumanMessage(content='where Pavan works?'),\n  AIMessage(content='Pavan works at SingleStore.')]}"},"execution_count":183,"metadata":{},"output_type":"execute_result"}],"source":"memory.load_memory_variables({})"},{"cell_type":"code","execution_count":184,"id":"34f96866-6c4b-41a2-bafb-d550e30dd4fa","metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:56:32.495876Z","iopub.status.busy":"2023-12-20T06:56:32.495629Z","iopub.status.idle":"2023-12-20T06:56:34.716300Z","shell.execute_reply":"2023-12-20T06:56:34.715739Z","shell.execute_reply.started":"2023-12-20T06:56:32.495858Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":"{'answer': AIMessage(content='Pavan actually works at SingleStore.'),\n 'docs': [Document(page_content='Pavan works at SingleStore as a Technology Evangelist')]}"},"execution_count":184,"metadata":{},"output_type":"execute_result"}],"source":"inputs = {\"question\": \"but where Pavan really works?\"}\nresult = final_chain.invoke(inputs)\nresult"},{"cell_type":"code","execution_count":null,"id":"35dfb4b7-6293-4e20-8a1c-7c869ba6db73","metadata":{"language":"python","trusted":true},"outputs":[],"source":""}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"ef511a14-4713-491d-890d-f7aff864ff0a","defaultDatabase":"pavandatabase"}},"nbformat":4,"nbformat_minor":5}